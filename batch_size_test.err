/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 1: setenv: command not found
/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 2: setenv: command not found
/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 3: setenv: command not found
/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 4: setenv: command not found
/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 34: syntax error near unexpected token `"${1}"'
/data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/etc/profile.d/conda.csh: line 34: `    switch ( "${1}" )'
/scratch4/lhyman6/conda/llavaenv/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 5/5 [00:00<00:00, 12264.05it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:02<00:09,  2.33s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:04<00:07,  2.38s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:06<00:04,  2.30s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:09<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:09<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:09<00:00,  1.97s/it]
Traceback (most recent call last):
  File "/data/lhyman6/OCR/scripts_newvision/llama/compute_optimal_batch_size.py", line 103, in <module>
    success = test_batch_size(mid, images)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/lhyman6/OCR/scripts_newvision/llama/compute_optimal_batch_size.py", line 66, in test_batch_size
    inputs = processor(
             ^^^^^^^^^^
  File "/scratch4/lhyman6/conda/llavaenv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py", line 313, in __call__
    raise ValueError(
ValueError: The number of image token (6) should be the same as in the number of provided images (6)
srun: error: icgpu05: task 0: Exited with exit code 1
